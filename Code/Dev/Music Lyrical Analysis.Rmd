---
title: "Music Lyrical Analysis. Unpacking musical preferences with R"
author: "Bree McLennan (www.breemclennan.com)"
date: "10 June 2018"
output: html_document
    #toc: true
    #toc_depth: 2
    #toc_float: true
    #theme: cerulean
    #highlight: haddock
    #df_print: paged
    #self_contained: yes
    #fig_caption: true
---

```{r global_options, include=FALSE}
## insert libraries here
library(dplyr)
library(knitr) # for dynamic reporting
library(stringr)
library(lubridate)
library(ggrepel)
library(wordcloud)
library(gridExtra) #viewing multiple plots together
library(tidyverse)
library(tidytext)
library(feather)
library(glue)
library(rprojroot)
library(purrr) #reduce and map functions
library(qdap)
library(ggplot2) #visualizations
library(kableExtra) # create a nicely formated HTML table
library(formattable) # for the color_tile function

#if (!require('RWordPress')) { #required for WordPress publishing
#  devtools::install_github(c("duncantl/XMLRPC", "duncantl/RWordPress"))
#}
library(RWordPress)

########################################
options(scipen = 10000)
options(knitr.table.format = "html") 
#opts_chunk$set(dev = 'pdf') #for plot rendering. Need to add fig.width and fig.height params to chunks
opts_chunk$set(cache = FALSE, echo = FALSE, warning = FALSE, message = FALSE)

#######################################
# Global themes
# ggplot2 custom theme settings
theme_lyrics <- function(aticks = element_blank(),
                         pgminor = element_blank(),
                         lt = element_blank(),
                         lp = "none")
{
  theme(plot.title = element_text(hjust = 0.5), #Center the title
        axis.ticks = aticks, #Set axis ticks to on or off
        panel.grid.minor = pgminor, #Turn the minor grid lines on or off
        legend.title = lt, #Turn the legend title on or off
        legend.position = lp) #Turn the legend on or off
}

#Customize the text tables for consistency using HTML formatting
my_kable_styling <- function(dat, caption) {
  kable(dat, "html", escape = FALSE, caption = caption) %>%
    kable_styling(bootstrap_options = c("striped", "condensed", "bordered"),
                  full_width = FALSE)
}

titles.format <- theme(plot.title = element_text(face = "bold", size = 13, color = 'grey50'),
                       plot.subtitle = element_text(color = 'grey50'),
                       axis.title = element_text(size = 9 , color='grey50'), 
                       axis.text = element_text(size = 9, color = 'grey50'),
                       plot.margin = unit(c(0.3,0.3,0.3,0.3), "cm"))

```

```{r data_setup, include=FALSE }

`%ni%` <- Negate(`%in%`)
# Define a function that computes file paths relative to where root .git folder is located
F <- is_git_root$make_fix_file() 
# Example usage: F("Data/Raw") , F("Data/Processed")

#Load images
image01_path <- F("Docs/ExploringMusicPart1.jpg")
image02_path <- F("Docs/DataConsiderations_LyricSheets_01.jpg")
image03_path <- F("Docs/DataConsiderations_LyricSheets_02.jpg")
image04_path <- F("Docs/Exploration_AlbumWordCountGantt.jpeg")
image05_path <- F("Data/Processed/SongSim_AllSongsJPG_RESIZE_v1.jpg") #Song Sim Poster

# Read in ready made source datasets
# SPOTIFY DATA
raw.SpotifyArtistAlbumTrackData <- read_feather(F("Data/Raw/raw.SpotifyArtistAlbumTrackData.feather"))

#-----------------------------------
# Pre Spotify Merge Data
wrk.data <- read_feather(glue(F("Data/Raw/raw.AllMusicLyrics.feather")))
wrk.01_Data_Prep <- wrk.data %>%
  mutate(BINTrackIsInstrumental = ifelse(style_name == "body" & trimws(text) == "[Instrumental]", 1, 0)) %>%
  mutate(KEYTrackName = toupper(trimws(CATTrackName)))
       
# QDAP CHECKS  ==========================
qview(wrk.01_Data_Prep)   
check_text(wrk.01_Data_Prep$text, file = F("Data/Raw/QDAPCheckText_wrk.01_Data_Prep.txt")) 

# Applying QDAP cleanup recommendations
wrk.01_Data_Prep$text <- replace_number(wrk.01_Data_Prep$text, num.paste = TRUE, remove = FALSE)
wrk.01_Data_Prep$text <- incomplete_replace(wrk.01_Data_Prep$text)
wrk.01_Data_Prep$text <- comma_spacer(wrk.01_Data_Prep$text)
wrk.01_Data_Prep$text <- clean(wrk.01_Data_Prep$text)
wrk.01_Data_Prep$text <- scrubber(wrk.01_Data_Prep$text, fix.comma = TRUE, fix.space = TRUE)

# Read in main text analysis dataset
wrk.01_DataPrep_LyricsWithSpotify <- read_feather(F("Data/Processed/wrk.01_DataPrep_LyricsWithSpotify.feather"))

```

```{r "CoverImage", echo=FALSE, out.width = "80%"}
# Render cover picture
include_graphics(image01_path)
```

&nbsp;

## Introduction, influences and inspirations
I have loved music since the day I was created. I love to be surrounded by glorious sounds and music I can really connect with. I’m by no means a musician or a sound engineer, I’m just a simple lover and enthusiast of listening to (and sometimes singing along with) music.

My family greatly influenced this musical enthusiasm. I grew up in a family full of music listening enthusiasts and “ninja singers” (people who sing when they think no one is around or can hear them!). My Dad influenced me with his eclectic collection of classic rock and famous mainstream songwriters from the 60’s through to the 80’s. From my Dad, I learned very early on to appreciate the crystal-clear sound vinyl records offer as well as quality stereo equipment. My Mum influenced me with her regular listening to radio stations, in particular Gold 104 FM (Melbourne Australia) and random sing-alongs in the car. My brother influenced me with his electrical engineering talents. I distinctly remember as a young kid the day he created his first car-boot boom box. Thundering rumbles of finely tuned bass could be heard from 3 blocks away in tranquil suburbia, and of course it was 90’s techno pop, electronica and occasionally Jamiroquai! 

So how did all this intriguing musical enthusiasm influence me?

I was always drawn to classic and hard rock. I’ve always been fascinated with the interaction of sound compositions and poetic lyrical prose. Being an athlete since I was 9, I recognised early on how sounds and lyrics could influence my performances. There’s music to psych you up or calm you down, and rhymes to help you stay in time! 

I discovered my fan-girl love for Irish rock group U2 when I was 14. It was their album “All That You Can’t Leave Behind” which got my attention. I then did what any obsessed fan-girl would do. I researched everything humanly possible about their music, and in addition to knowing every lyric to every song U2 ever wrote, I consequently ended up learning a great deal about many musical-related and life-experience topics. Things like the guitars and complex sound effects The Edge uses, Bono’s public speaking, song writing talents and stage presence, Larry’s masterful methods of how to stay out of the public spotlight while protecting his band, and Adam’s talents for creative collaboration and sophisticated, artistic conversation.

As the years moved on, I began to open up and diversify my music collection. I have my husband to thank in part for this, introducing me to heavy metal and modern electronic genres. These days, my music interest is eclectic. In any single day I enjoy listening to anything between Eminem and Enya, Rammstein to Bobby McFerrin, Tibetan Buddhist Monk chanting to Dragonforce Through the Fire and the Flames. Yes, I’m also a huge fan of the Audiosurf game series, and Guitar Hero!

&nbsp;

## The data of music: What’s this analysis about? What's the purpose and objective?

There’s not many days that go by where I’m not listening to music. I spend hours every day working away while listening to music, many hours creating an inadvertent fashion trend with my headphones and many hours with my thoughts randomly jumping in with playful musical commentary.

More recently, this thought pattern commentary has been circulating in my head:

  *	“This is such an eclectic playlist, **how do you make sense** of such a diverse collection of music?”
  *	“How on earth are these pieces of music even **related or connected?**” “Yes Joshua Tree, I’m referring to you, I still haven’t found what I’m looking for and its not Bullet the Blue Sky!”
  *	“What makes this song **unique, special, similar and different** to another song in your playlist…surely Led Zeppelin’s Kashmir is some kind of random outlier?”
  *	“Does this album actually **tell a story** or have a **meaning**?”
  *	“Hey Bree, you are a **data scientist** by trade. **Music IS data**, could you do something **useful and insightful** with it to **find some answers**?”
  
On that last comment, my inner kid sparked up and went “ooh this could be so much fun, we can learn, write, and do an analysis with sound engineering, signal processing, text mining and natural language processing”. I very quickly realised to cover off all of those topics in a single blog wouldn’t be doing any of those single topics any justice. I would need to chunk-down these topics into separate blogs. So for this blog, I’m choosing to do one smaller topic, with great love:

**A music lyrical analysis!** 

Working with the lyrical components for a selected collection of music data. We shall apply **text mining** and **natural language processing** techniques to this data to explore the above questions, build insights and find some answers.

The target audience for this analysis is aimed at the general population of music enthusiasts, data scientists, data-folk, and anyone who’s ever wondered what on earth Led Zeppelin’s Kashmir was about.

&nbsp;

## Technical guiding questions for designing this analysis 

As we flow through this analysis I’m seeking to weave in my responses to four key technical questions which are relevant for text mining and natural language processing:

  1.	How will you acquire and structure the data?
  2.	How can we visualise this data to tell us a story and help us make meaningful sense of the data?
  3.	What are the important key words and n-gram constructs associated with each artist’s album?
  4.	What are the sentiments and emotional representations of each song and album?
  5.	What topics emerge from the albums? Can machine learning be useful here?

&nbsp;

## Project workflow 

This project will be written in R, with the [repository link here](https://github.com/breemclennan/music_lyric_analysi)

**Sequencing:**

  * **1.	Data considerations**
  
    + a.  Artist and album selection
    + b.	Obtaining lyrics
    + c.	Converting lyric sheets into a useful dataset
    + d.  Data cleaning & pre processing
    + e.	Additional data: Using the Spotify API
    + f.	Observing the specific and unique nature of music lyrics in a text analysis context
    + g.	Variable names and the source dataset	

    &nbsp;
    
  * **2.	Manual Data Exploration**
  
    + a.  Creating tokens & Data Wrangling 
    + b.  Identifying vocal and instrumental songs
    + c.  Word counts by song & album
    + d.  Wordclouds
    + e.  Lexical diversity (vocabulary)
    + f.  song lyrics self-similarity matrices (SongSim) & repetition
    + g.  Term Frequency Inverse Document Frequency (TF-IDF)
    
    &nbsp;
    
  * **3.	Sentiment Analysis & Natural Language Processing (NLP)** 
  
    + a.  NRC Emotional Sentiment
    + b.  NGrams, bi-grams & tri-grams
    + c.  Bi-gram network analysis
    + d.  Pair-wise comparisons
    + e.  Album similarity
    + f.  Song dissimilarity (agreement between lyrics)
    
    &nbsp;
    
  * **4.	Unsupervised Machine Learning**
  
    + a.	Topic modelling: Structured Topic Modelling (STM)
    
    &nbsp;
    
  * **5.	Findings & Learnings**
  
    +	Findings
    + Learnings, gotchas, traps for young players
    + Where to next, part 2
    
  &nbsp;
  
  * **6.	References**
  
   &nbsp;

## 1. Data Considerations

**Intellectual property & copyrights**

Because we are working with copyrighted material in reference to music lyrics, the copyright belongs to the artists and songwriters who created the songs and the lyrics.

&nbsp;

**Artist and album selection**

After much deliberation and consulting with friends and family, I decided to select 6 artists and an album from each of these artists. 

&nbsp;

+---------------+-------------------+---------------+-------------+--------------------------------------+---------------+---------------------------------------------------------+
| Artist        | Album             | Release Year  | Genre       | Tracks                               |  Review Tags  |  Other Notes & Rationale for selection                  |
+===============+===================+===============+=============+======================================+===============+=========================================================+
| Daft Punk     | Discovery         | 2001          | Electronic  | 1.	One More Time                    | Electronic,   | Aerodynamic, Crescendolls, Nightvision, Superheroes,    |  
|               |                   |               |             | 2.	Aerodynamic                      | House,        | High Life, Voyager, Viridis Quo and Short Circuit       |
|               |                   |               |             | 3.	Digital Love                     | Rock,         | are instrumental songs. We will include these for sound |
|               |                   |               |             | 4.	Harder, Better, Faster, Stronger | Techno,       | analysis in a subsequent exploration of music analysis. |
|               |                   |               |             | 5.	Crescendolls                     | Funk,         |                                                         |
|               |                   |               |             | 6.	Nightvision                      | Modern Disco  | Music video movie “Interstella 555:                     |
|               |                   |               |             | 7.	Superheroes                      |               | The Story of the Secret Star System”.                   |
|               |                   |               |             | 8.	High Life                        |               | The film is the visual realization of Discovery.        |
|               |                   |               |             | 9.	Something About Us               |               |                                                         |
|               |                   |               |             | 10. Voyager                          |               | http://www.imdb.com/title/tt0368667/                    |
|               |                   |               |             | 11. Veridis Quo                      |               |                                                         |
|               |                   |               |             | 12. Short Circuit                    |               | Bree’s favourite Daft Punk album.                       |
|               |                   |               |             | 13. Face to Face                     |               |                                                         |
|               |                   |               |             | 14. Too Long                         |               |                                                         |
|               |                   |               |             |                                      |               |                                                         |
|               |                   |               |             |                                      |               |                                                         |
+---------------+-------------------+---------------+-------------+--------------------------------------+---------------+---------------------------------------------------------+
| U2            | The Joshua Tree   | 1987          | Rock        | 1.	Where the streets have no name   | Rock,         | One of the biggest selling albums of all time.          |  
|               |                   |               |             | 2.	I still haven't found what       | Gospel,       | 30th Anniversary of its release in 2017                 |
|               |                   |               |             | I'm looking for                      |               | saw U2 take it on tour.                                 |
|               |                   |               |             | 3.	With or without you              |               |                                                         |
|               |                   |               |             | 4.	Bullet the blue sky              |               |                                                         |
|               |                   |               |             | 5.	Running to stand still           |               |                                                         |
|               |                   |               |             | 6.	Red hill mining town             |               |                                                         |
|               |                   |               |             | 7.	In God's country                 |               |                                                         |
|               |                   |               |             | 8.	Trip through your wires          |               |                                                         |
|               |                   |               |             | 9.  One tree hill                    |               |                                                         |
|               |                   |               |             | 10. Exit                             |               |                                                         |
|               |                   |               |             | 11. Mothers of the disappeared       |               |                                                         |
|               |                   |               |             |                                      |               |                                                         |
+---------------+-------------------+---------------+-------------+--------------------------------------+---------------+---------------------------------------------------------+
| Elton John    | Honky Chateau     | 1972          | Rock        | 1.  Honky Cat                        | Rock,         | Rolling Stone believes this was the album which         |  
|               |                   |               |             | 2.  Mellow                           | Pop,          | marked the transformation of Elton John from gentle     |
|               |                   |               |             | 3.  I think I'm going to kill myself | Rock & Roll   | singer/songwriter to a legitimate rock star.            |
|               |                   |               |             | 4.  Susie (Dramas)                   |               |                                                         |
|               |                   |               |             | 5.  Rocket Man (I think it's going   |               | https://www.rollingstone.com/music/pictures/readers-poll-the-10-best-elton-john-albums-20130918/5-honky-chateau-3-78-9                                                        |
|               |                   |               |             |     to be a long, long time)         |               |                                                         |
|               |                   |               |             | 6.  Salvation                        |               |                                                         |
|               |                   |               |             | 7.  Slave                            |               |                                                         |
|               |                   |               |             | 8.  Amy                              |               |                                                         |
|               |                   |               |             | 9.  Mona Lisa and Mad Hatters        |               |                                                         |
|               |                   |               |             | 10. Hercules                         |               |                                                         |
|               |                   |               |             |                                      |               |                                                         |
+---------------+-------------------+---------------+-------------+--------------------------------------+---------------+---------------------------------------------------------+
| Killswitch    | Alive or Just     | 2002          | Metal Core  | 1.	Numbered Days                    | Hardcore      | Loudwire suggests this is the greatest                  |  
| Engage        | Breathing         |               |             | 2.	Self Revolution                  | Metal,        | album KsE produced.                                     |
|               |                   |               |             | 3.	Fixation on the Darkness         |               |                                                         |
|               |                   |               |             | 4.	My Last Serenade                 |               | http://loudwire.com/killswitch-engage-albums-ranked/    |
|               |                   |               |             | 5.	Life to Lifeless                 |               |                                                         |
|               |                   |               |             | 6.	Just Barely Breathing            |               |                                                         |
|               |                   |               |             | 7.	To The Sons of Man               |               |                                                         |
|               |                   |               |             | 8.	Temple from Within               |               |                                                         |
|               |                   |               |             | 9.	The Element of One               |               |                                                         |
|               |                   |               |             | 10. Vide Infra                       |               |                                                         |
|               |                   |               |             | 11. Without a Name                   |               |                                                         |
|               |                   |               |             | 12. Rise Inside                      |               |                                                         |
|               |                   |               |             | 13. When the Balance is Broken       |               |                                                         |
|               |                   |               |             |                                      |               |                                                         |
+---------------+-------------------+---------------+-------------+--------------------------------------+---------------+---------------------------------------------------------+
| Iron          | Powerslave        | 1984          | Heavy Metal | 1.	Aces High                        | Hard Rock,    | LouderSound suggests this is the greatest               |  
| Maiden        |                   |               |             | 2.	Two Minutes to Midnight          | Heavy Metal   | album Iron Maiden produced.                             |
|               |                   |               |             | 3.	Losfer Words (Big 'Orra)         |               |                                                         |
|               |                   |               |             | 4.  Flash of the Blade               |               | https://www.loudersound.com/features/every-iron-maiden-album-ranked-from-worst-to-best    |
|               |                   |               |             | 5.	The Duellists                    |               |                                                         |
|               |                   |               |             | 6.	Back in the Village              |               |                                                         |
|               |                   |               |             | 7.	Powerslave                       |               |                                                         |
|               |                   |               |             | 8.	Rime of the Ancient Mariner      |               |                                                         |
|               |                   |               |             |                                      |               |                                                         |
+---------------+-------------------+---------------+-------------+--------------------------------------+---------------+---------------------------------------------------------+
| Led           | Physical Graffiti | 1975          | Rock        | 1.	Custard Pie                      | Hard Rock,    | Bree wants to inspect Kashmir further.                 |  
| Zeppelin      |                   |               |             | 2.	The Rover                        | Heavy Metal   |                                                         |
|               |                   |               |             | 3.	In my Time of Dying              |               | Bron-Yr-Aur is an instrumental                          |
|               |                   |               |             | 4.  Houses of the Holy               |               |                                                         |
|               |                   |               |             | 5.	Trampled Under Foot              |               |                                                         |
|               |                   |               |             | 6.	Kashmir                          |               |                                                         |
|               |                   |               |             | 7.	In the Light                     |               |                                                         |
|               |                   |               |             | 8.	Bron-Yr-Aur                      |               |                                                         |
|               |                   |               |             |                                      |               |                                                         |
+---------------+-------------------+---------------+-------------+--------------------------------------+---------------+---------------------------------------------------------+


&nbsp;
 
**Obtaining lyrics**

I made a conscious decision to download the lyrics for the selected albums, manually. This was achieved by googling, finding the correct lyric sheets and then copying and pasting into Microsoft Word. I could have just as easily set up an R script to web-scrape, but I wanted to observe and have full control over the state and structure the lyrics were being stored as and apply some very specific formats, for a reason, which I will explain in the next section.

&nbsp;
 
**Converting lyric sheets into a useful dataset**

For the source dataset we’re creating, we want to maintain the “structural integrity” of the music lyrics as we import them into data frames. This means our dataset looks the same way the lyric sheet looks. We have rows for album title, rows for song titles, rows for each verse and each chorus.

**Why?**

Music is all about patterns, sequences and time signatures. Lyrics are written differently to many other forms of written communication. Lyrics are also interwoven with sound, else it would be just poetry or a short story. It would be inappropriate at this point to treat the lyrics as one giant “word pool”. We need to maintain hierarchial groupings and identify which lyrics belong with which artist and album. Let's firstly observe the lyrics in as close to the original structure as they were written.

**How do we do this?**

Let’s keep the lyric sheets in `.docx` format for now and check the integrity of the style formats.
There’s magic in the little “¶” button on the paragraph menu pane in Microsoft Word. 

For each lyric sheet we have, turn on **paragraph marks** and make the following adjustments:

  * Configure styles for Heading 1, Heading 2, Heading 3, Normal body and spacing after paragraph
  * Heading 1 – Artist name
  * Heading 2 – Album name
  * Heading 3 – song title name
  * Song lyrics – Normal body

Each verse and chorus are separated by a paragraph. Individual lines within verses and choruses separated with carriage return (Enter key), with a single space at the end of each line.

Between each style component used, separate these with a single paragraph. Paragraphs will create new rows for our dataset, as will differentiating styles.

Where a song is instrumental, use `"[Instrumental]"` as a consistent tag across all lyric sheets for ease of flagging these songs for filtering later.

&nbsp;

```{r "DataConsideration_LyricSheet01", echo=FALSE, out.width = "40%"}
# Render lyric sheet setup example
include_graphics(image02_path)
```

&nbsp;

We can use the `officer` and `qdapTools` packages to read in the collection of lyric sheet documents:

```{r "ReadInWordDocument", echo=TRUE, eval=TRUE}
# Working with word documents (docx):
# Read in each file and use docx_summary() to map the styles used in each document as records in a dataframe.
# Then apply some common hirarchial groupings: Artist, Album, Track Name, and add in verse line counters.
library(officer)
library(qdapTools)
library(zoo)

doc02 <- read_docx(F("Data/Raw/U2 - The Joshua Tree.docx"))
raw.data02 <- docx_summary(doc02) %>%
  mutate(CATMusicArtist = "U2",
         CATMusicAlbum = "The Joshua Tree",
         CATTrackName = ifelse(style_name == "heading 3", text, "None"),
         CATTrackName = zoo::na.locf(CATTrackName), #fill down track number
         style_name = ifelse(is.na(style_name), "body", style_name)
  ) %>%
  group_by(CATTrackName) %>%
  mutate(NUMTrackLyricLineNumber = sequence(n()) - 1) #using minus 1 so we dont include the main heading

```
&nbsp;

Our imported lyric sheet for **U2 - The Joshua Tree** has now become a nicely structured data frame. Here's an example of the first four records:

&nbsp;

```{r "DataConsideration_LyricSheet02", echo=FALSE, out.width = "75%"}
# Render lyric sheet result in dataframe

raw.data02 %>%
  head(n = 4) %>%
  kable("html", escape = FALSE, align = "c", caption = "Raw dataset for: U2 - The Joshua Tree (first 4 records)") %>%
  kable_styling(bootstrap_options = c("striped", "condensed", "bordered"), full_width = FALSE)

#include_graphics(image03_path)
```

&nbsp;

We will repeat the above steps for the other Artists and Albums in our selection and append the datasets together.

Next, we will perform some data checks and cleanup using the `QDAP` package. 

```{r "QDAPChecks", echo=TRUE, eval=FALSE}

# Using the dataset which contains all raw imported lyric sheets from the previous step:
# Tidy up the track name variable for when we need to use this as a merge key
# Identify the songs which are instrumental. We will filter these out for this analysis.

wrk.01_Data_Prep <- wrk.data %>%
  mutate(BINTrackIsInstrumental = ifelse(style_name == "body" & trimws(text) == "[Instrumental]", 1, 0)) %>%
  mutate(KEYTrackName = toupper(trimws(CATTrackName)))
       
# Use QDAP qview to identify suggestions for tidy up. Results will be written to a text file.
qview(wrk.01_Data_Prep)   
check_text(wrk.01_Data_Prep$text, file=F("Data/Raw/QDAPCheckText_wrk.01_Data_Prep.txt")) 

# Applying QDAP cleanup recommendations
wrk.01_Data_Prep$text <- replace_number(wrk.01_Data_Prep$text, num.paste = TRUE, remove = FALSE)
wrk.01_Data_Prep$text <- incomplete_replace(wrk.01_Data_Prep$text)
wrk.01_Data_Prep$text <- comma_spacer(wrk.01_Data_Prep$text)
wrk.01_Data_Prep$text <- clean(wrk.01_Data_Prep$text)
wrk.01_Data_Prep$text <- scrubber(wrk.01_Data_Prep$text, fix.comma = TRUE, fix.space = TRUE)

```

&nbsp;

**Additional data: Using the Spotify API**

I thought it would be useful to explore alternative sources of data to complement the lyrical dataset we just created. In my exploration, I came across the `spotifyr` package [with more details here](https://github.com/charlie86/spotifyr). After setting up a [Spotify developers account](https://beta.developer.spotify.com/dashboard/) I was able to obtain the necessary **“client ID”** and **“client secret”** tokens, and set these as environment variables to use in the spotifyr functions.

&nbsp;
```{r "SampleSpotifyAPICode", echo=TRUE, eval=FALSE}
#devtools::install_github('charlie86/spotifyr')
#install.packages('spotifyr')
library(spotifyr)
# Reference: https://github.com/charlie86/spotifyr

# app name "MusicLyricAnalysis1"
Sys.setenv(SPOTIFY_CLIENT_ID = "ADD TOKEN HERE")
Sys.setenv(SPOTIFY_CLIENT_SECRET = "ADD TOKEN HERE")

access_token <- get_spotify_access_token()

#Extract data from spotify
spotify_df_U2 <- get_artist_audio_features('U2',access_token)
spotify_df_DaftPunk <- get_artist_audio_features('Daft Punk',access_token)
spotify_df_EltonJohn <- get_artist_audio_features('Elton John',access_token)
spotify_df_LedZeppelin <- get_artist_audio_features('Led Zeppelin',access_token)
spotify_df_KillswitchEngage <- get_artist_audio_features('Killswitch Engage',access_token)
spotify_df_IronMaiden <- get_artist_audio_features('Iron Maiden',access_token)

spotify_U2_filtered <- filter(spotify_df_U2, album_name == "The Joshua Tree (Deluxe)") #we have extra live songs
spotify_DaftPunk_filtered <- filter(spotify_df_DaftPunk, album_name == "Discovery")
spotify_EltonJohn_filtered <- filter(spotify_df_EltonJohn, album_name == "Honky Chateau") #no results found
spotify_LedZeppelin_filtered <- filter(spotify_df_LedZeppelin, album_name == "Physical Graffiti")
spotify_KillswitchEngage_filtered <- filter(spotify_df_KillswitchEngage, album_name == "Alive or Just Breathing [Topshelf Edition]")
spotify_IronMaiden_filtered <- filter(spotify_df_IronMaiden, album_name == "Powerslave (1998 Remastered Edition)")

# We can keep these datasets in data frame format for now, dataset size is tiny.
raw.SpotifyArtistList <- list(spotify_U2_filtered, spotify_DaftPunk_filtered, spotify_EltonJohn_filtered,
                              spotify_LedZeppelin_filtered, spotify_KillswitchEngage_filtered, spotify_IronMaiden_filtered)
# Append all above raw datasets together
raw.SpotifyArtistAlbumTrackData <- rbindlist(raw.SpotifyArtistList) %>%
  mutate(KEYTrackName = toupper(trimws(track_name)))

# Save Feather file from 
write_feather(raw.SpotifyArtistAlbumTrackData, F("Data/Raw/raw.SpotifyArtistAlbumTrackData.feather"))

wrk.01_DataPrep_LyricsWithSpotify <- list(wrk.01_Data_Prep, raw.SpotifyArtistAlbumTrackData) %>%
  reduce(left_join, by = c("KEYTrackName" = "KEYTrackName"))

# Save Feather file from 
write_feather(wrk.01_DataPrep_LyricsWithSpotify, F("Data/Processed/wrk.01_DataPrep_LyricsWithSpotify.feather"))
```
&nbsp;

Inspecting the Spotify data for the collection of albums:

```{r "CheckSpotifyDataset", echo=TRUE, eval=TRUE}
# Check over the dataset
glimpse(raw.SpotifyArtistAlbumTrackData)

```


After attempting to extract the desired albums from the selected artists, I discovered that not all albums or songs from the albums were available on spotify. For example, **Elton John’s Honky Chateau** was not available to extract, instead only single tracks were available via a best-of album. For **U2’s The Joshua Tree**, the original release album is not available, only the deluxe edition which comes with extra live performance tracks. Similar situation for **Iron Maiden’s Powerslave**.

With this information, I decided that the Spotify data is simply a _"nice to have"_ and will not be entirely useful to this analysis. I would very much have liked for it to cover all artists, all albums and all songs in the collection. 

We will leave the spotify variables in the merged dataset, but we won't use them in this analysis.

&nbsp;

```{r "SpotifyTracksNotMatching", echo=TRUE, eval=TRUE}

CheckSpotify <- select(raw.SpotifyArtistAlbumTrackData,album_name, track_name)
checkSpotify_NotMatchingSource <- anti_join(CheckSpotify, wrk.01_Data_Prep, by = c("track_name" = "CATTrackName") ) #all spotify songs not matching our source data
glimpse(select(checkSpotify_NotMatchingSource,album_name, track_name ))

```
&nbsp;


**Observing the specific and unique nature of music lyrics in a text analysis context**

A few things we can observe and acknowledge so far:

*	Some songs will be instrumental. The raw lyric sheets will only contain `“[Instrumental]”` for instrumental songs. We can filter these out of our analysis and re-use these in subsequent analysis. Perhaps for signal or beat detection analysis!
* Each lyric “line” is meaningful in the flow of a song. Each line can be linked to subsequent lines via rhyming and context. We expect the lyric sheets to loosely resemble poetry and we expect a higher instance of repetition, because music is full of patterns (unless we’re dealing with some kind of random jam session or jazz genres!)
*	The number of songs will vary per artist and album. Some albums will have more songs than others. We need to be mindful of any analysis utilising word counts or averages
* In reality: The lyrics are interwoven with an audio track. This analysis is like staring at words in segregated silence. With the audio track interwoven this adds the dimensions of time series, verbal intonation and speech/verbal patterns, and emotional sentiment, all of which lead us to interpret the lyrics differently to how we would analysing lyrics in isolation.

&nbsp;

**Variable names and the source dataset**
	
Here is a summary of the source dataset we’ll use for this analysis. It is one row per album track. All lyrics for each track are contained within a single variable **TXTAllTrackLyrics**. The end of each lyric line is signified with `“<br>"` tag.


```{r "VariableNamesSourceDataset", echo=TRUE, eval=TRUE}

# Create a new dataframe with one row of lyrics for each track (instead of multiple rows per verse/chorus)
wrk.02_TextAnalysis_00 <-  wrk.01_DataPrep_LyricsWithSpotify %>% 
  group_by(CATTrackName) %>% 
  mutate(TXTAllTrackLyrics = paste0(text, sep = "<br>", collapse = " ")) %>%
  mutate(NUMMaxLyricLines = max(as.numeric(NUMTrackLyricLineNumber)))

# Create a dataset with one row per song. One variable & record to hold all lyrics for a song.
wrk.02_TextAnalysis_01 <- wrk.02_TextAnalysis_00 %>%
  filter(style_name == "heading 3")

# lets now remove songs which were purely instrumental only
wrk.02_TextAnalysis_02 <- wrk.02_TextAnalysis_01 %>%
  filter(str_detect(TXTAllTrackLyrics, "Instrumental") == FALSE )

#Summary
glimpse(wrk.02_TextAnalysis_02)


```

From this dataset, the most important variables we will be using frequently will be:

* **text** & **TXTAllTrackLyrics**, usage will depend on the character string structure we need for text analysis functions.
* **CATMusicArtist**, our main grouping variable
* **CATMusicAlbum**, our secondary grouping variable
* **CATTrackName**, most granular grouping variable
* **BINTrackIsInstrumental**, for filtering out songs with no lyrics

&nbsp;


## 2. Manual Data Exploration

**a. Creating tokens & Data Wrangling**

Our dataset is almost ready for exploration. There's a few remaining data wrangling steps to complete:

  1. Manually identify any _"undesirable words"_ in the context of lyrics. Sometimes we see markers in the lyric sheets like "chorus", "repeat x3" etc.
  2. We have the option to remove stop words at this point, although I would like to leave them in for intial exploration and remove them when we begin more detailed text analysis.
  3. Create lyric line tokens, split the lyrics into individual verses.
  4. Create lyric word tokens, split the lyrics into individual words.
  5. Create numeric counter of how many words per song, per album & artist.

&nbsp;


```{r "Exploration_Tokens", echo=TRUE, eval=TRUE}
library(tidytext)

#Identify any specific/customisable words we wish to eliminate later on
undesirable_words <- c("chorus", "lyrics", "verse")

#Create lyric verse tokens using tidytext [dataset will be one row per verse]
lineToken <- wrk.02_TextAnalysis_02 %>%
  ungroup() %>%
  unnest_tokens(line, TXTAllTrackLyrics, token = stringr::str_split, pattern = '<br>') %>% #break the lyrics into verses
  mutate(lineCount = row_number()) #Create a line counter so we know which verse record is which

# Create lyric word tokens and apply tidy text format [dataset will be one row per lyric word]
# We have the option to remove stop words at this point. 
# Selecting not to do this yet, as we wish to visually observe the raw form of the dataset.
wordToken <-  lineToken %>% 
  unnest_tokens(word, line) %>%  #Break the lyrics into individual words
  # anti_join(stop_words) %>% #TM/tidytext removing stop words
  filter(!word %in% undesirable_words) #removing custom configured stop words

# Add in full word counts for each song (non-distinct)
wrk.02_TextAnalysis_03_WordCount <- wordToken %>%
  group_by(CATMusicArtist,CATMusicAlbum, CATTrackName) %>%
  summarise(num_words = n()) %>%
  arrange(desc(num_words)) 

```

&nbsp;

**b. Identifying vocal and instrumental songs**

We need to identify which songs are instrumental so we can exclude them for this analysis. Not surprisingly, more than half of the songs on **Daft Punk's Discovery** are instrumental.

&nbsp;

```{r "Exploration_Instrumental", echo=FALSE, eval=TRUE}

# Number of songs by artist
wrk.02_TextAnalysis_03_SongPerArtist <- wrk.02_TextAnalysis_01 %>%
  ungroup() %>%
  mutate(BINSongIsInstrumental = as.factor(ifelse(str_detect(TXTAllTrackLyrics, "Instrumental") == TRUE, 1,0 ))) %>%
  mutate(BINSongIsInstrumental = as.numeric(BINSongIsInstrumental)) %>%
  group_by(CATMusicArtist,CATMusicAlbum) %>%
  add_tally() %>% #count the total number of rows in the by group assign to variable "n"
  rename(NUMTotalSongsForArtist = n) %>% # RENAME PARAMETERS (NEW NAME = OLD NAME).
  ungroup() 

#instrumental songs
instrumental <- filter(wrk.02_TextAnalysis_03_SongPerArtist, str_detect(TXTAllTrackLyrics, "Instrumental") == TRUE )

instrumental %>%
  select(CATMusicArtist, CATMusicAlbum, CATTrackName) %>%
  kable("html", escape = FALSE, align = "c", caption = "Instrumental Songs to Exclude from Analysis") %>%
  kable_styling(bootstrap_options = 
                  c("striped", "condensed", "bordered"), full_width = FALSE)
```

&nbsp;

**c. Word counts by song & album**

With our dataset now ready for exploration, let's inspect these questions:

* How many songs with lyrics are available to work with?
* What are the raw word counts for these songs?

We have **59** songs to work with, and **Iron Maiden's Rime of the Ancient Mariner** has a very large word count at **650 words**, significantly higher than any other song in our dataset. 

Could this song's lyrics skew any subsequent analysis we will be performing?

&nbsp;
```{r "Exploration_SongWordCountTotal", echo=FALSE, eval=TRUE}

#Summarise our source dataset
glimpse(wrk.02_TextAnalysis_03_WordCount)

# Songs by the highest unique word count
wrk.02_TextAnalysis_03_WordCount %>%
  ungroup(num_words, CATTrackName) %>%
  mutate(num_words = color_bar("lightblue")(num_words)) %>%
  mutate(CATTrackName = color_tile("lightpink","lightpink")(CATTrackName)) %>%
  kable("html", escape = FALSE, align = "c", caption = "Songs With Highest Total Word Count") %>%
  kable_styling(bootstrap_options = 
                  c("striped", "condensed", "bordered"), 
                full_width = FALSE)

```
&nbsp;

While this table shows us the raw individual word counts for each song, it doesn't clearly illustrate the Artist-Album groupings and total word counts for Artist-Album. Some questions here:

* How many songs do we have for each Artist & Album?
* What is the "wordiest" album in the collection? Could this be used as a basic indicator of the balance between story telling and sound engineering?

We must be careful here about using total word counts. Considering Daft Punk’s Discovery had many songs excluded due to them being instrumental, there are less songs available to contribute to an overall word count.

&nbsp;
```{r "Exploration_AlbumWordCountGantt", echo=FALSE, eval=TRUE, out.width = "100%", fig.width=14, fig.height=8}

#TOTAL WORD COUNT: USING QDAP
wrk.02_TextAnalysis_03_QDAPWordCount <- with(wrk.02_TextAnalysis_02, qdap::gantt_rep(rm.var = CATMusicArtist, text.var = TXTAllTrackLyrics, grouping.var = CATTrackName ))

gantt_wrap(wrk.02_TextAnalysis_03_QDAPWordCount,
           plot.var = "CATMusicArtist", fill.var = "CATTrackName",
           border.color = "black",
           legend.position = "bottom",
           major.line.freq = 250,
           ncol = 2,
           size = 7,
           border.size = 4,
           border.width = .4,
           title = "Total word count for each artist & album, segmented by song") 

#include_graphics(image04_path)

```

&nbsp;


**d. Wordclouds**

We can visualise the raw word counts using word clouds. The intention here is to get some initial, basic insight as to the common words for each artist & album. 

We do need to be careful with the usage and context of these visualisations here because we know some songs were designed for repetition and certain words will dominate for this reason.

For this section we will use the `wordcloud` package and create some word clouds.

&nbsp;
```{r "Exploration_WordClouds_00", echo=FALSE, eval=TRUE, fig.width=5, fig.height=5}

# Most common words in each album
wrk.02_TextAnalysis_03_CommonWordsAlbum <- wordToken %>%
  anti_join(stop_words) %>% # remove stop words, allow us to see some more meaningful results
  count(CATMusicArtist, CATMusicAlbum, word, sort = TRUE) %>%
  ungroup()

library(wordcloud2) #needs htmlwidgets
library(wordcloud) #static images
```

**Daft Punk - Discovery**
```{r "Exploration_WordClouds_01", echo=FALSE, eval=TRUE, fig.width=5, fig.height=5}
# WORD CLOUDS - for each album
#==== DAFT PUNK
albums_wordcloud_DaftPunk <- wrk.02_TextAnalysis_03_CommonWordsAlbum %>%
as.data.frame(albums_wordcloud) %>%
  filter(CATMusicArtist == "Daft Punk") %>%
  select(word, n) 

##wordcloud2(albums_wordcloud_DaftPunk[1:88, ], size = .5) #wont render if rownum set to more than whats in the dataset
wordcloud(albums_wordcloud_DaftPunk$word, albums_wordcloud_DaftPunk$n, min.freq=1, random.order=FALSE, max.words = 100, 
          colors=brewer.pal(8, "Dark2"), use.r.layout=TRUE)
```

**U2 - The Joshua Tree**
```{r "Exploration_WordClouds_02", echo=FALSE, eval=TRUE, fig.width=5, fig.height=5}
#==== U2
albums_wordcloud_U2 <- wrk.02_TextAnalysis_03_CommonWordsAlbum %>%
  as.data.frame(albums_wordcloud) %>%
  filter(CATMusicArtist == "U2") %>%
  select(word, n) 
#wordcloud2(albums_wordcloud_U2[1:100, ], size = .5)
wordcloud(albums_wordcloud_U2$word, albums_wordcloud_U2$n, min.freq=1, random.order=FALSE, max.words = 100,
          colors=brewer.pal(8, "Dark2"), use.r.layout=TRUE)

```

**Elton John - Honky Chateau**
```{r "Exploration_WordClouds_03", echo=FALSE, eval=TRUE, fig.width=5, fig.height=5}
#==== Elton John
albums_wordcloud_Elton <- wrk.02_TextAnalysis_03_CommonWordsAlbum %>%
  as.data.frame(albums_wordcloud) %>%
  filter(CATMusicArtist == "Elton John") %>%
  select(word, n) 
#wordcloud2(albums_wordcloud_Elton[1:100, ], size = .5)
wordcloud(albums_wordcloud_Elton$word, albums_wordcloud_Elton$n, min.freq=1, random.order=FALSE, max.words = 100,
          colors=brewer.pal(8, "Dark2"), use.r.layout=TRUE)

```

**Led Zeppelin**
```{r "Exploration_WordClouds_04", echo=FALSE, eval=TRUE, fig.width=5, fig.height=5}
#==== Led Zeppelin
albums_wordcloud_LedZep <- wrk.02_TextAnalysis_03_CommonWordsAlbum %>%
  as.data.frame(albums_wordcloud) %>%
  filter(CATMusicArtist == "Led Zeppelin") %>%
  select(word, n) 
#wordcloud2(albums_wordcloud_LedZep[1:100, ], size = .5)
wordcloud(albums_wordcloud_LedZep$word, albums_wordcloud_LedZep$n, min.freq=1, random.order=FALSE, max.words = 100,
          colors=brewer.pal(8, "Dark2"), use.r.layout=TRUE)

```

**Killswitch Engage**
```{r "Exploration_WordClouds_05", echo=FALSE, eval=TRUE, fig.width=5, fig.height=5}

#==== Killswitch Engage
albums_wordcloud_KsE <- wrk.02_TextAnalysis_03_CommonWordsAlbum %>%
  as.data.frame(albums_wordcloud) %>%
  filter(CATMusicArtist == "Killswitch Engage") %>%
  select(word, n) 
#wordcloud2(albums_wordcloud_KsE[1:100, ], size = .5)
wordcloud(albums_wordcloud_KsE$word, albums_wordcloud_KsE$n,min.freq=1, random.order=FALSE, max.words = 100,
          colors=brewer.pal(8, "Dark2"), use.r.layout=TRUE)

```

**Iron Maiden**
```{r "Exploration_WordClouds_06", echo=FALSE, eval=TRUE, fig.width=5, fig.height=5}
#==== Iron Maiden
albums_wordcloud_IronMaiden <- wrk.02_TextAnalysis_03_CommonWordsAlbum %>%
  as.data.frame(albums_wordcloud) %>%
  filter(CATMusicArtist == "Iron Maiden") %>%
  select(word, n) 
#wordcloud2(albums_wordcloud_IronMaiden[1:100, ], size = .5)
wordcloud(albums_wordcloud_IronMaiden$word, albums_wordcloud_IronMaiden$n, min.freq=1, random.order=FALSE, max.words = 100,
          colors=brewer.pal(8, "Dark2"), use.r.layout=TRUE)

```

```{r "Exploration_WordClouds_RenderAll", echo=FALSE, eval=TRUE, fig.width=5, fig.height=5, fig.align='left'}
#library(wordcloud)
#par(mfrow = c(6, 1))
```

&nbsp;

**e. Lexical diversity (vocabulary)**

Time to explore the depth of each song's lyrical vocabulary, we will refer to this as _"lexical diversity"_.

A question at this point is: Could the larger the vocabulary for a song (and therefore artist) be an indicator of great story telling?

In calculating the lexical diversity we will:

* Remove stop words
* Work with a dataset which is one row per word (un-nested, token by word)
* Group by Artist & Album
* Count by distinct words used in each song
* Visualise using a pirateplot box plot, from the `yarrr` package

&nbsp;

```{r "Exploration_LexicalDiversity", echo=FALSE, eval=TRUE, fig.width=10, fig.height=7}
# Let's observe the lexical diversity, or vocabulary, of each of the song lyrics.
# Assumption: the more diverse the lyrics, the larger the vocabulary
# Using a continuous dependent variable "word_count", as a function of the categorical independent variable, album.
LexicalDensity_01 <- wordToken %>%
  anti_join(stop_words) %>% 
  group_by(CATMusicArtist, CATMusicAlbum, CATTrackName) %>%
  mutate(CATArtistAlbumTrack = paste(CATMusicArtist, CATMusicAlbum, CATTrackName, sep = " - ")) %>%
  mutate(CATArtistAlbum = paste(CATMusicArtist, CATMusicAlbum, sep = " - ")) %>%
  mutate(word_count = n_distinct(word)) %>%
  select(CATMusicArtist, CATMusicAlbum, CATTrackName, CATArtistAlbum, CATArtistAlbumTrack, word_count) %>%
  distinct() %>% #Summarise to one record per song, distinct word count
  ungroup()

LexicalDensity_01 %>%
  arrange(desc(word_count)) %>%
  kable("html", escape = FALSE, align = "c", caption = "Lexical (Vocabulary) Diversity for Each Artist, Album and Song") %>%
  kable_styling(bootstrap_options = c("striped", "condensed", "bordered"), full_width = FALSE)

library(yarrr)
#Lets draw the plot
pirateplot(formula =  word_count ~ CATMusicArtist, #Formula
           data = LexicalDensity_01, #Data frame
           xlab = NULL, ylab = "Distinct Word Count for Each Song", #Axis labels
           main = "Lexical (Vocabulary) Diversity for Each Artist & Album", #Plot title
           pal = "espresso", #Color scheme
           back.col = gray(.98), # Add light gray background
           gl.col = "gray", # Gray gridlines
           gl.lwd = c(.75, 0),
           inf.f.o = .6, # Turn up inf filling
           inf.disp = "rect", # Wrap inference around bean
           bean.b.o = .4, # Turn down bean borders
           quant = c(.25, .75), # 25th and 75th quantiles
           quant.col = "black", # Black quantile lines
           point.o = .2, #Points
           avg.line.o = 1, #Turn on the Average/Mean line
           theme = 2, #Theme
           point.pch = 16, #Point `pch` type
           point.cex = 1.5, #Point size
           jitter.val = .1, #Turn on jitter to see the songs better
           cex.lab = 1, cex.names = .9) #Axis label size
```

It becomes immediately obvious, **Iron Maiden's Powerslave** contains a range of more and less lexically dense songs.
Iron Maiden's song **"Rime of the Ancient Mariner"** is by far an outlier in this visualisation, at **167** distinct words.

On the lower end of the scale, **Daft Punk's Discovery** and **Killswitch Engage's Alive or Just Breathing** appear to have a smaller vocabulary. Some human experiential insights from these musical compositions suggest that these albums are very engineered for audio and sound experience. **Daft Punk's Discovery** could be described as a dance record, while **Killswitch Engage's Alive or Just Breathing** may have been designed to get the most out of vocally _"growling"_ lyrics and so careful selection of words to achieve this purpose could be what we are observing in a lower vocabulary range.

In the mid-range of the lexical diversity we see Elton John, Led Zeppelin and U2, perhaps this is where the balance between audio experience and story telling can be observed?

&nbsp;


**f.  Song lyrics self-similarity matrices (SongSim) & repetition**

We have observed the lexical diversity for our collection of songs. Let's now take a look at lyrical repetition.

Measuring and observing lyrical (or word) repetition is very relevant for this analysis as our context is music. Repetition can be observed in both instrumental waveforms and in lyrical structure. Ever had a song stuck in your head, repeating over and over? 

The challenge here is to identify and use a visualisation which neatly and clearly descibes repetition for our collection of songs.

Enter package `songsim`.

SongSim uses self-similarity matrices to visualise patterns of repetition in text. Each word (lyric) of a song forms a row and a column of the matrix. The cell at position (x, y) is filled in if the x-th and y-th words of the song are the same. [For a more technical explanation check out the package author's site here](https://colinmorris.github.io/SongSim/#/about/intro).

A self-similarity matrix is used to answer the question "which parts of this text thing are alike?".

To get started, let's setup our process flow for SongSim and take a look at Led Zeppelin's Kashmir.

&nbsp;
```{r "Exploration_SongSim_KashmirInteractive", echo=FALSE, eval=TRUE, fig.width=6, fig.height=6}
library(songsim)
library(heatmaply)
# Subset out source dataset by Artist, Song, and keep lyrics only
SongSim_LedZepKashmir <- wrk.01_DataPrep_LyricsWithSpotify %>%
  filter(CATMusicArtist == "Led Zeppelin" & CATTrackName == "Kashmir") %>%
  filter(style_name == "body") %>%
  select(text)

# Write out our subset to a text file. This will be used as input for SongSim
# This will write to root level project folder - we can move it to a more appropriate location later.
fileConn <- file("SongSim_LedZepKashmir.txt")
writeLines(SongSim_LedZepKashmir$text, fileConn)
close(fileConn)

resLedZepKashmir <- songsim(path = (F("Data/Raw/SongSim_LedZepKashmir.txt")),interactiveMode = FALSE, colorfulMode = TRUE,
                            mainTitle = "Led Zeppelin - Kashmir",
                            plotOptions = c(width = 4, height = 4))

```
&nbsp;

Most of Kashmir has very little repetition. As we progress down the black diagonal line to the bottom right of the square we begin to see some pattern "blobs" coloured in blue, purple and pink, this is attributed to the repeated lyrics:

> Ooh, yeah-yeah, ooh, yeah-yeah, when I'm down... 

> Ooh, yeah-yeah, ooh, yeah-yeah, well I'm down, so down 

> Ooh, my baby, ooh, my baby, let me take you there 


> Let me take you there. Let me take you there  

The "Colorful" mode of the SongSim matrix plot assigns a unique color to each repeated word (words appearing only once are black). When there are several repeated themes, this can make it easier to distinguish them.

```{r "Exploration_SongSim_DataSetup", include=FALSE }
library(songsim)
library(heatmaply)
library(glue)
SongSim_All_01 <- wrk.01_DataPrep_LyricsWithSpotify %>%
  filter(style_name == "body" & text != "[Instrumental]") %>%
  mutate(CATMusicAlbum = as.factor(CATMusicAlbum),
         CATMusicArtist = as.factor(CATMusicArtist),
         CATTrackName = as.factor(CATTrackName)) %>%
  mutate(CATArtistAlbumTrack = paste(CATMusicArtist, CATMusicAlbum, CATTrackName, sep = " - ")) %>%
  select(CATArtistAlbumTrack, text)

SongList <- tapply(SongSim_All_01$text, SongSim_All_01$CATArtistAlbumTrack, matrix, byrow = TRUE)

RenderSongSim <- lapply(names(SongList),
                        function(x, SongList) songsim(path = paste((F("Data/Raw")),"/", x ,".txt", sep = ""),
                                                      colorfulMode = TRUE,
                                                      interactiveMode = FALSE, 
                                                      #singleColor = "blue",
                                                      plotOptions = c(width = 4, height = 4),
                                                      mainTitle = x),
                                                      SongList)

# What is the repetition level for the songs?
distinctSongList <- SongSim_All_01 %>%
  group_by(CATArtistAlbumTrack) %>%
  distinct(CATArtistAlbumTrack) %>%
  ungroup()
distinctSongList <- as.data.frame(distinctSongList)

#Unpack the songsim big list
length(RenderSongSim)
str(RenderSongSim[[1]])
SongSim_Repetition <- RenderSongSim %>% map_dbl("repetitiveness")
df <- as.data.frame(SongSim_Repetition)

#Dataset with repetitiveness measure and the artist+album+track column
Song_Repetition_DF <- data.frame(bind_cols(distinctSongList, df))
Song_Repetition_DF <- Song_Repetition_DF %>%
  mutate(CATArtistAlbumTrack_split = CATArtistAlbumTrack) %>%
  mutate(SongSim_Repetition = as.numeric(SongSim_Repetition)) %>%
  separate(CATArtistAlbumTrack_split, c("CATMusicArtist", "CATMusicAlbum", "CATTrackName"), " - ", extra = "merge")

```
&nbsp;
The SongSim matrices also come with some handy parameters:

* `$ songMat` - this is the matrix structure for the SongSim plot
* `$ repetitiveness` - this quantifies how repetitive a song is. It is a simple mean of the upper triangle of the matrix. The larger the value, the more repetitive the song.

We can create songsim matrices for our collection of songs and then compare `repetitiveness` scores as a method of assessing lyrical repetition (or lyrical density).

&nbsp;
```{r "Exploration_SongSim_Repetition", echo=FALSE, eval=TRUE, fig.width=10, fig.height=7}

Song_Repetition_DF %>%
  arrange(desc(SongSim_Repetition)) %>%
  kable("html", escape = FALSE, align = "c", caption = "SongSim Lyrical Repetitiveness for Each Song by Artist") %>%
  kable_styling(bootstrap_options = c("striped", "condensed", "bordered"), full_width = FALSE)


library(yarrr)
pirateplot(formula =  SongSim_Repetition ~ CATMusicArtist, #Formula
           data = Song_Repetition_DF, #Data frame
           xlab = "All Songs", ylab = "Lyrical Repetitiveness (Song Sim)", #Axis labels
           main = "SongSim Repetitiveness for Each Song by Artist", #Plot title
           pal = "espresso", #Color scheme
           back.col = gray(.98), # Add light gray background
           gl.col = "gray", # Gray gridlines
           gl.lwd = c(.75, 0),
           inf.f.o = .6, # Turn up inf filling
           inf.disp = "rect", # Wrap inference around bean
           bean.b.o = .4, # Turn down bean borders
           quant = c(.25, .75), # 25th and 75th quantiles
           quant.col = "black", # Black quantile lines
           point.o = .2, #Points
           avg.line.o = 1, #Turn on the Average/Mean line
           theme = 2, #Theme
           point.pch = 16, #Point `pch` type
           point.cex = 1.5, #Point size
           jitter.val = .1, #Turn on jitter to see the songs better
           cex.lab = 1, cex.names = .9) #Axis label size
```

Is it so surprising to see **Daft Punk's Discovery** with the highest average lyrical repetitiveness? Interesting it also has the widest range of repetitiveness.

Curious to observe **U2's The Joshua Tree** has the lowest average and the smallest range of lyrical repetitiveness. The grouping of songs appear to be very consistent in terms of lyrical repetition.


So what do all of these songs look like as SongSim matrices? We have an opportunity here to create some _"data art"_.

[Click here to see the SongSim poster we created for the collection of songs in this analysis](https://github.com/breemclennan/music_lyric_analysis/blob/master/Data/Processed/SongSim_AllSongsJPG_RESIZE.jpg).

&nbsp;

Some notable mentions from the "SongSim Matrix Poster":

* Entire patterned square: Daft Punk's "Harder, Better, Faster, Stronger" is a great example of visualised pop music. The chorus is basically the entire song. 
* Small checkerboard-like patterns: Most of Elton John's songs only have a small number of words within a repetition.
* Verses and Bridges "gutter" patterns: Most of Iron Maiden's and U2's songs appear to follow an `into - verse - chorus - verse - chorus - outro` pattern
* Broken Diagonal patterns: Most of Killswitch Engages's songs suggest a variation on the chorus or another major repeating section. Most of their songs are structured with `verse - chorus - verse - chorus`, but at the very end, some words moved around or swapped out.
* Hybrid of "gutter" and "broken diagonal"" patterns: Very much Led Zeppelin.


This has certainly unconvered some very interesting insights about how the songs in the collection are structured, and maybe even shed some light on the Artist's preferences toward lyrical song writing.


&nbsp;

**g.  Term Frequency Inverse Document Frequency (TF-IDF)**

Let's now address quantifying how important various lyrics (words) are in a song with respect to an album.

The **Term Frequency - Inverse Document Frequency** (TF-IDF for short), is a measure of:

Term Frequency * Inverse Document Frequency

* The Term Frequency, the number of times a word is counted in a document

**Multiplied by**

* 1/DF, or 1 divided by the number of documents that contain each word

With the TF and IDF combined, a word's (or a lyric's) importance is adjusted for how rarely it is used. The assumption with TF-IDF is that words that appear more frequently in a document (or a song) should be given a higher weighting, _unless_ the word also appears in many documents (or songs). 

For our analysis we can use TF-IDF to identify which words are important to each of the albums in the collection, and compared across albums. We expect the albums to differ in terms of subject/topic, content and sentiment, we therefore expect the frequency of words to differ between albums, the TF-IDF metric will highlight these differences.

So let's take a look at word importance through the lense of TF-IDF


```{r "Exploration_TFIDF", include=FALSE}

tidy_MusicLyrics <- lineToken %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)

  #filter(word != "")

tidy_MusicLyrics %>% #check the word list and identify any further words to filter out above.
  count(word, sort = TRUE)

```

```{r "Exploration_TFIDF_Plots", echo=FALSE, eval=TRUE, fig.width=10, fig.height=7}
MusicLyrics_tf_idf <- tidy_MusicLyrics %>%
  count(CATMusicArtist, word, sort = TRUE) %>%
  bind_tf_idf(word, CATMusicArtist, n) %>%
  arrange(-tf_idf) %>%
  group_by(CATMusicArtist) %>%
  top_n(10) %>% #the top 10 highest td-idf words
  ungroup()

MusicLyrics_tf_idf %>%
  kable("html", escape = FALSE, align = "c", caption = "TF, IDF and TF-IDF scores for collection of songs and albums") %>%
  kable_styling(bootstrap_options = c("striped", "condensed", "bordered"), full_width = FALSE)

MusicLyrics_tf_idf %>%
  mutate(word = reorder(word, tf_idf)) %>%
  ggplot(aes(word, tf_idf, fill = CATMusicArtist)) +
  geom_col(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~ CATMusicArtist, scales = "free", ncol = 3) +
  #scale_x_reordered() +
  coord_flip() +
  theme(strip.text=element_text(size=11)) +
  labs(x = NULL, y = "TF-IDF Score",
       title = "Highest TF-IDF words in collection of Music Albums",
       subtitle = "Individual songs focus on different themes and narrative elements")


```
&nbsp;

We see lots of familiar lyric words here which we can trace clearly back to individual songs. There are also specific narrative elements for individual songs, like **Daft Punk's** "Harder, Better, Faster, Stronger", we can see almost the entire chorus structure (we do know it's highly repetitive!). True to the nature of the TF-IDF metric, the words to this song are really only found in this song and very unlikely elsewhere.

Same goes for "rocket" in Elton John's Rocket Man, "(two) minutes (to) midnight" in Iron Maiden, "numbered days" in Killswitch Engage, "Kashmir" in Led Zeppelin, and "red hill mining town" in U2. These are all curiously exclusive to the songs they are found in.

While this really doesn't tell us anything new, this can still be useful insight and information to be aware of prior to designing and training any models and exploring topic modelling.

Some questions we can ask before heading into sentiment analysis and machine learning:

1. Do we need to perform more data preparation?
2. Stemming: do we need to remove suffixes from words and reduce down to the common word origin? Is it appropriate?
3. Lemmatization: do we need to remove inflectional endings of words, and return the base or dictionary form of a word (which is known as the lemma)? 
4. Advanved concept in sentiment analysis: Is it appropriate to simply replace some certain words with more frequently used synonyms (semantically similar peers) and/or hypernyms (common parents)? This would be used to address lexicon word matching challenges, between the words in the text versus the lexicon used.
5. Do we need to construct our own lexicon for the sentiment analysis?

&nbsp;


## 3. Sentiment Analysis & Natural Language Processing (NLP)

Sentiment analysis is a type of text mining which aims to determine the opinion and subjectivity of its content. When applied to song lyrics, the results can be representative of the artist's attitude as well as their influences.

Natural Language Processing (NLP) is another methodology used in mining text. It tries to decipher the ambiguities in written language by tokenization, clustering, extracting entity and word relationships, and using algorithms to identify themes and quantify subjective information. This analysis in earlier sections touched on the basics of NLP, via exploring the lexical complexity of song lyrics (word frequencies, lexical diversity "vocabulary" and lexical density "repetition").

&nbsp;

**a.  NRC Emotional Sentiment**

There are different methods which can be used for sentiment analysis. For this analysis we will explore our collection of songs using a predefined lexical dictionary (lexicon) named `NRC`.

The NRC lexicon assigns words into one or more of ten categories: positive, negative, anger, anticipation, disgust, fear, joy, sadness, surprise, and trust.

We will use the `tidytext` package and call in the `NRC` lexicon by using the `get_sentiments()` function when creating our data frame.


Let's observe how the NRC lexicon triages our song lyric words into the emotional sentiments.

```{r "Exploration_NRCSentiment", echo=FALSE, eval=TRUE, fig.width=10, fig.height=10}
#METHOD 1: USING TIDY TEXT
SongSentiment_TidyText_NRC <- wordToken %>%
  anti_join(stop_words) %>% 
  inner_join(get_sentiments("nrc")) %>%
  filter(!sentiment %in% c("positive", "negative")) %>%
  group_by(CATMusicArtist ,sentiment) %>%
  count(word, CATMusicArtist, sort = TRUE) %>%
  arrange(desc(n)) %>%
  slice(seq_len(8)) %>% #consider top_n() from dplyr also
  ungroup()

#PLOT NRC SENTIMENT BY ARTST & ALBUM (ALL WORDS)
SongSentiment_TidyText_NRC %>%
  #Set `y = 1` to just plot one variable and use word as the label
  ggplot(aes(word, 1, label = word, fill = sentiment )) +
  #You want the words, not the points
  geom_point(color = "transparent") +
  #Make sure the labels don't overlap
  geom_label_repel(force = 1,nudge_y = .5, nudge_x = .5,  
                   direction = "both",
                   box.padding = 0.04,
                   segment.color = "transparent",
                   size = 3) +
  facet_grid(CATMusicArtist~sentiment) +
  theme_lyrics() +
  theme(axis.text.y = element_blank(), axis.text.x = element_blank(),
        axis.title.x = element_text(size = 6),
        panel.grid = element_blank(), panel.background = element_blank(),
        panel.border = element_rect("lightgray", fill = NA),
        strip.text.x = element_text(size = 9)) +
  xlab(NULL) + ylab(NULL) +
  ggtitle("NRC Sentiment by Artist & Album") +
  coord_flip()

```
&nbsp;

This is a very dense visualisation, difficult to distinguise any clear patterns.

Let's summarise this down to word counts by emotional sentiment.

```{r "Exploration_NRCSentiment_Summary", echo=FALSE, eval=TRUE, fig.width=7, fig.height=5}

#SongSentiment_TidyText_NRC
wordToken %>%
  anti_join(stop_words) %>% 
  inner_join(get_sentiments("nrc")) %>%
  filter(!sentiment %in% c("positive", "negative")) %>%
  group_by(CATMusicArtist ,sentiment) %>%
  summarise(word_count = n()) %>%
  ungroup() %>%
  mutate(sentiment = reorder(sentiment, word_count)) %>%
  ggplot(aes(sentiment, word_count, fill = -word_count)) +
  facet_wrap(~CATMusicArtist) +
  geom_col() +
  guides(fill = FALSE) +
  theme_lyrics() +
  labs(x = "NRC Sentiment", y = "Word Count") +
  ggtitle("NRC Sentiment by Artist & Album") +
  coord_flip()
```

So how do these album's make us feel when we listen to them?

I have always suspected **Daft Punk's Discovery** to be jovial and energetic. I am glad to see anticipation, joy and trust rate highly for this album.

Equally for **Killswitch Engage's Alive or Just Breathing**, this album tells stories with much sadness, anger and fear. Not very surprising these emotions rate highly for this album.


&nbsp;

**b. NGrams, bi-grams & tri-grams**

Earlier in this analysis we explored single word (or unigram) frequency counts. This section is dedicated to exploring what precedes and follows the most common words we have identified in our collection of songs.

We have the option at this point to remove stop words and undesirable words before calculating the bi-grams and tri-grams. For this piece, only the undesirable words have been removed. It would be interesting to observe the "direction" of the song lyrics, are songs written as one person toward another, a group of people, us versus them, collective "we", directive "you". Let's take a look!

&nbsp;

```{r "Exploration_BiGrams", echo=FALSE, eval=TRUE, fig.width=10, fig.height=7}
#REF: https://www.datacamp.com/community/tutorials/sentiment-analysis-R#prepwork

 BiGrams <- lineToken %>%
  unnest_tokens(ngram, line, token = "ngrams", n = 2) %>%  #Break the lyrics into individual words
  #anti_join(stop_words) %>% #removing stop words
  #filter(!ngram %in% undesirable_words) %>%
  group_by(CATMusicArtist,CATMusicAlbum, CATTrackName) %>%
  dplyr::count(ngram, sort = TRUE) %>%
  ungroup()

  TriGrams <- lineToken %>%
  unnest_tokens(ngram, line, token = "ngrams", n = 3) %>%  #Break the lyrics into individual words
  #anti_join(stop_words) %>% #removing stop words
  filter(!ngram %in% undesirable_words) %>%
  group_by(CATMusicArtist,CATMusicAlbum, CATTrackName) %>%
  count(ngram, sort = TRUE) 

library(ggplot2)
b.G <- BiGrams %>%
  group_by(CATMusicArtist) %>%
  mutate(ngram = reorder(ngram, n, sum)) %>%
  slice(1:10) %>%
  ungroup() %>%
  #to reorder the x axis by sum of n, add in reorder() to aes(x= ..)
  ggplot(aes(x = reorder(ngram, n, sum), n, fill = CATMusicArtist)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ CATMusicArtist, scales = "free") +
  ylab("Most Frequent Bi-Grams") +
  xlab('Bi-grams') +
  ggtitle("Bi-Grams for each Artist & Album") +
  coord_flip() 
  

b.G 
```


```{r "Exploration_TriGrams", echo=FALSE, eval=TRUE, fig.width=10, fig.height=7}
t.G <- TriGrams %>%
  group_by(CATMusicArtist) %>%
  mutate(ngram = reorder(ngram, n, sum)) %>%
  slice(1:10) %>%
  ungroup() %>%
  #to reorder the x axis by sum of n, add in reorder() to aes(x= ..)
  ggplot(aes(reorder(ngram, n, sum), n, fill = CATMusicArtist)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ CATMusicArtist, scales = "free") +
  ylab("Most Frequent Tri-Grams") +
  xlab('Tri-grams') +
  ggtitle("Tri-Grams for each Artist & Album") +
  coord_flip() 

t.G 


```
&nbsp;

The lasting "sentiments" from obseving these bi-grams and tri-grams:

* Daft Punk - The lyrical repetitiveness is very obvious, strongest of all the artists. Ngram structure points toward "being in the moment" and self-enjoyment.
* Elton John - Less ngram frequency, with a common thread of thankfulness ("thank") and chill ("mellow")
* Iron Maiden - Strong themes of returning to a communal "village" and anticipating "midnight"
* Killswitch Engage - Written from the experiences of the first person ("i am", "me in") and observing the passing of "time"
* Led Zeppelin - The writer's observations of relationships with people ("you didn't", "hey mama", "love")
* U2 - The writer's observations of life journeys, observations with people ("haven't found", "bullet the blue", "you give") and foreign places ("streets")

&nbsp;


**c. Bi-gram network analysis**

From our Bi-Gram constructs we can create a network graph using the `ggraph` and `igraph` packages. We can arrange words into connected nodes, with selected "centring words" at the centres.

From our earlier inspection of unigram word frequencies, the following high-frequency "centering words" have been selected

`"hey","feel","gonna","people","yeah","love","light","time", "life"`

Our dataset will be grouped up, to represent all songs, for all artists and albums.


&nbsp;

```{r "Exploration_BiGrams_Network", echo=FALSE, eval=TRUE, fig.width=7, fig.height=7}
centre_words <- c("hey","feel","gonna","people","yeah","love","light","time", "life")

bigrams_separated <- BiGrams %>%
  separate(ngram, c("word1", "word2"), sep = " ")

library(ggraph)
library(igraph)
library(tidytext)
centre_bigrams <- bigrams_separated %>%
  select(word1, word2, n) %>%
  filter(word1 %in% centre_words) %>%
  group_by(word1) %>%
  slice(seq_len(20)) %>%
  ungroup()

bigram_graph <- centre_bigrams %>%
  graph_from_data_frame() #From `igraph`

set.seed(2016)

a <- grid::arrow(type = "closed", length = unit(.10, "inches"))

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link() +
  geom_node_point(color = "lightblue", size = 5) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  ggtitle("Bi-Gram Network for All Songs") +
  theme_void()
```


This is just a simple network graph to demonstrate the various methods we can use to visualise our song lyric data.

For any songwriter's out there, perhaps this could be useful in identifying lyric constructs.


&nbsp;


**d.  Pair-wise comparisons**

Which songs are similar to each other in lyrical content? We can explore this by finding the pairwise correlation of lyric (word) frequencies within each song, using the `pairwise_cor()` function from the `widyr` package.


We will remove stop words for this analysis, to allow us to observe more meaningful results.

&nbsp;

```{r "Exploration_PairWiseCompare", echo=FALSE, eval=TRUE, fig.width=7, fig.height=4}

library(widyr)
library(ggraph)
library(igraph)

# Most common words in each song
wrk.02_TextAnalysis_03_CommonWordsSong <- wordToken %>%
  anti_join(stop_words) %>% # remove stop words, allow us to see some more meaningful results
  count(CATTrackName, word, sort = TRUE) %>%
  ungroup()

song_cors <- wrk.02_TextAnalysis_03_CommonWordsSong %>%
  pairwise_cor(CATTrackName, word, n, sort = TRUE)

song_cors %>%
  kable("html", escape = FALSE, align = "c", caption = "Pairwise Correlation - Song Links by Words Used") %>%
  kable_styling(bootstrap_options = c("striped", "condensed", "bordered"), full_width = FALSE)

set.seed(4321)

song_cors %>%
  filter(correlation > .4) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(alpha = correlation, width = correlation)) +
  geom_node_point(size = 6, color = "lightblue") +
  geom_node_text(aes(label = name), repel = TRUE) +
  ggtitle("Pairwise Correlation Plot - Song Links by Words Used") +
  theme_void()

```

Well this is curious, **Elton John's Mona Lisa and Mad Hatters** and **Led Zeppelin's Down by the Seaside** have a connection with a correlation greater than 0.4. Does this mean they are similar songs?

Interesting that no other songs had a high enough correlation to be considered as significant.


&nbsp;

**e.  Album similarity**

Using the `QDAP` package we have access to a function called `trans_venn()`. Since we just observed pairwise correlations between songs, let's take a look at similarity between albums, visualised as a venn diagram.


```{r "Exploration_AlbumSimilarity", echo=FALSE, eval=TRUE, fig.width=10, fig.height=5}
VennDiagram <- with(wrk.02_TextAnalysis_02 , qdap::trans_venn(text.var = text, grouping.var = CATMusicArtist, title.name="Album lyric similarity", legend.location = "topright"))

```

It appears **U2's The Joshua Tree** is a versatile linking centroid in this venn diagram. Can the other albums realistically be "linked" together via The Joshua Tree?


&nbsp;

**f.  Song dissimilarity (agreement between lyrics)**

Just like the album similarity we calculated in the previous section, we can do something similar for songs. Still using the `QDAP` package, we can use the `Dissimilarity()` function. We can perform dissimilarity statistics, using the distance function to calculate dissimilarity statistics by grouping variables.

The `Dissimilarity()` function will return a matrix of dissimilarity values, which is the agreement between text, or song. We will plot this matrix as a dendogram and identify some potential clusters.

&nbsp;

```{r "Exploration_SongDisimilarity", echo=FALSE, eval=TRUE, fig.width=15, fig.height=15}

SongDendogram <- with(wrk.02_TextAnalysis_02,  qdap::Dissimilarity(text.var = text, grouping.var = list(CATMusicArtist, CATTrackName), method = "prop",
              diag = FALSE, upper = FALSE, p = 2))
fit <- hclust(SongDendogram)
plot(fit)
## draw dendrogram with red borders around the 3 clusters
rect.hclust(fit, k = 14, border = c("red", "blue", "green", "purple", "orange", "brown", "seagreen") )  

```

This dendogram offers us a very alternative view of how similar and different the individual songs in the collection are.

  
&nbsp;
    
## 4. Unsupervised Machine Learning
  
**a. Topic modelling: Structured Topic Modelling (STM)**

Topic modeling is a method for unsupervised classification of documents, similar to clustering on numeric data, which finds natural groups of items even when we’re not sure what we’re looking for or what our target is.

Can we identify any meaningful groups or themes in our collection of songs?

For this piece, we will use Structured Topic Modelling (STM) and make use of the packages `quanteda` and `stm`.


One of the drawbacks of STM is the need to select the number of topics "K" to train the model with. Fortunately, the `stm` package comes with  lots of functions and support for choosing an appropriate number of topics for the model.


&nbsp;

```{r "TopicModel_STM", echo=FALSE, eval=TRUE}

#TOPIC MODEL (Structured Topic Model, STM)
#inspiration reference: https://juliasilge.com/blog/sherlock-holmes-stm/

#The stm() function take as its input a document-term matrix,
#either as a sparse matrix or a dfm from quanteda.

#Reference: http://thomaselliott.me/pdfs/earl/topic_modeling.html

# Next step is the processing workhorse. 
#  This actually does the topic modeling. 
# First, we can run stm with init.type=“Spectral” and K=0 
#  to have the algorithm calculate the appropriate number of topics itself.
# This does not mean the number of topics it finds is the true number of topics, 
# but it is a good place to start.
# 
# Spectral initialization uses a decomposition of the VxV word co-occurence matrix
# to identify “anchor” words - words that belong to only one topic and therefore identify that topic.
# The topic loadings of other words are then calculated based on these anchor words. 
# This processes is deterministic, so that the same values are always arrived at with the same VxV matrix. 
# The problem is that this process assumes that the VxV matrix is generated from the population of documents
# (or, put another way, assumes it is generated from an infinite number of documents). 
# Thus, the process does not behave well with infrequent words. The solution to this is to remove infrequent words,
# though one should still be careful if you don’t have a lot of documents.
# My guess is that I should use Spectral, but make sure it is robust to a series of LDA models (meaning that Spectral produces results as good as or better than LDA models).
# I also suspect that I don’t have enough documents to trust the number of models to use.

library(quanteda)
library(stm)

You could use either of these objects (sherlock_dfm or sherlock_sparse)
 as the input to stm(). For this analysis we will use the quanteda dfm object.


library(quanteda)
library(stm)

tidy_MusicLyrics <- lineToken %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)
  #filter(word != "")

tidy_MusicLyrics %>% #check the word list and identify any further words to filter out above.
  count(word, sort = TRUE)

MusicLyrics_dfm <- tidy_MusicLyrics %>%
  count(CATMusicArtist, word, sort = TRUE) %>%
  cast_dfm(CATMusicArtist, word, n)


#pre-process the text. This involves removing stop words (common words as well as user specified stop words), stemming words (to remove suffixes), and other basic steps to make the text ready for processing.
tidy_stemming_MusicLyrics <- textProcessor(tidy_MusicLyrics$word, meta = tidy_MusicLyrics, customstopwords = undesirable_words,
                                           stem = TRUE)
#prep the documents. In this step, I remove words that appear in less than 1 document, as well as words that appear in more than 60 articles. This helps remove some noise.
num.docs <- length(tidy_stemming_MusicLyrics$documents)
max.docs <- num.docs-2
out <- prepDocuments(tidy_stemming_MusicLyrics$documents, tidy_stemming_MusicLyrics$vocab, tidy_stemming_MusicLyrics$meta,
                     lower.thresh = 1,upper.thresh = max.docs)

# Check how many documents we have
texts <- tidy_MusicLyrics$word[-tidy_stemming_MusicLyrics$docs.removed]


# Train the model with 0 clusters K defined. Lets observe:
STM_topic_model <- stm(MusicLyrics_dfm, K = 0, seed=12345,
                       verbose = FALSE, init.type = "Spectral")

#The above analysis identifies 32 topics, below are common words for each of these topics:
labelTopics(STM_topic_model)

#Below graphs how common each topic is:
plot.STM(STM_topic_model,type = "summary", xlim = c(0, 0.1))


#plot exclusivity vs semantic coherence
topicQuality(STM_topic_model, documents = out$documents)

#Topic modelling
#stm, quanteda
#fitting the model:
#  unsupervised M learning
#which words contribute to which topics
#which topics contribute to which documents

#beta matrix: what are the words which contribute to each topic
#> plot the matrix, top 10 words in cluster

#gamma matrix:
#  how much did this document contribute to the topic?
#  how likely is this document to belong to this topic


STM_topic_model <- stm(MusicLyrics_dfm, K = 6, seed=12345, verbose = FALSE, init.type = "Spectral")

td_BetaMatrix <- tidy(STM_topic_model)

td_BetaMatrix %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  mutate(topic = paste0("Topic ", topic),
         term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = as.factor(topic))) +
  geom_col(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free_y") +
  coord_flip() +
  #scale_x_reordered() +
  labs(x = NULL, y = expression(beta),
       title = "Highest word probabilities for each topic",
       subtitle = "Different words are associated with different topics")

#Now let’s look at another kind of probability we get as output from topic modeling, 
# the probability that each document is generated from each topic.
td_GammaMatrix <- tidy(STM_topic_model, matrix = "gamma",                    
                 document_names = rownames(MusicLyrics_dfm))

ggplot(td_GammaMatrix, aes(gamma, fill = as.factor(topic))) +
  geom_histogram(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~ topic, ncol = 3) +
  labs(title = "Distribution of document probabilities for each topic",
       subtitle = "Each topic is associated with exactly 1 story",
       y = "Number of stories", x = expression(gamma))

#In this case, each short story is strongly associated with a single topic.
#Topic modeling doesn’t always work out this way,
#but I built a model here with a small number of documents (only 6) 
#and a relatively large number of topics compared to the number of documents.
#In any case, this is how we interpret these gamma probabilities; they tell us which topics are coming from which documents.

# We can see some interesting things; there are shifts through the collection
# as topic 3 stories come at the beginning and topic 5 stories come at the end. 
#Topic 5 focuses on words that sound like spooky mysteries happening at night,
#in houses with doors, and events that you see or hear, topic 1 is about lords, 
#ladies, and wives, and topic 2 is about… GEESE. You can use each tab in the app 
#to explore the topic modeling results in different ways.

```
&nbsp;

## 5.	Findings & Learnings
  
Findings

Learnings, gotchas, traps for young players


Where to next, part 2
    
&nbsp;
  
## 6.	References

Many hours have been spent researching approaches for designing and writing this analysis. Here’s some items I’d like to share
Inspirations for this piece
TV series “It might get loud” with The Edge (U2), Jimmy Page (Led Zeppelin), Jack White (The White Stripes)
Game: Audiosurf (visualising sound, beat detection algorithms and digital signal processing)

Text mining, NLP and Machine Learning with Music Lyrics
Prince analysis
https://www.datacamp.com/community/tutorials/R-nlp-machine-learning
https://www.datacamp.com/community/tutorials/sentiment-analysis-R
The Ramones
http://r-blog.salvaggio.net/?p=521
Rick and Morty
http://tamaszilagyi.com/blog/a-tidy-text-analysis-of-rick-and-morty/
50 Years of Pop Music Lyrics
https://github.com/walkerkq/musiclyrics
Radiohead & Using the Spotify API
http://www.rcharlie.com/post/fitter-happier/
https://github.com/charlie86/spotifyr
https://developer.spotify.com/web-api/object-model/#audio-features-object
http://rcharlie.net/sentify/

Alternative sentiment analysis: Using the “gloom” index to find depressing songs
http://blog.revolutionanalytics.com/2017/02/finding-radioheads-most-depressing-song-with-r.html
http://www.everydayanalytics.ca/2013/06/radiohead-lyrics-data-visualization-and-content-analysis.html

Alternative visualisations: Visualising songs as matrix structures and find repetitions
R Package song sim: http://giorasimchoni.com/2017/10/16/2017-10-16-repeat-yourself-the-songsim-package/

